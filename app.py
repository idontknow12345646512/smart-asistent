import streamlit as st
import google.generativeai as genai
from datetime import datetime
from shared import global_store 
import streamlit.components.v1 as components
from streamlit_mic_recorder import mic_recorder

st.set_page_config(page_title="S.M.A.R.T. Voice & Image", page_icon="ğŸ™ï¸")

# --- FUNKCE: AI MLUVÃ ÄŒESKY ---
def speak_text(text):
    # OÅ¡etÅ™enÃ­ textu pro JavaScript (odstranÄ›nÃ­ uvozovek a zalomenÃ­ Å™Ã¡dkÅ¯)
    safe_text = text.replace("'", "").replace('"', "").replace("\n", " ")
    js_code = f"""
        <script>
        window.speechSynthesis.cancel(); // ZastavÃ­ pÅ™edchozÃ­ mluvenÃ­, pokud jeÅ¡tÄ› bÄ›Å¾Ã­
        var msg = new SpeechSynthesisUtterance('{safe_text}');
        msg.lang = 'cs-CZ'; 
        msg.rate = 1.0; 
        window.speechSynthesis.speak(msg);
        </script>
    """
    components.html(js_code, height=0)

# --- SIDEBAR ---
with st.sidebar:
    st.title("âš™ï¸ SystÃ©m S.M.A.R.T.")
    voice_enabled = st.toggle("HlasovÃ¡ odpovÄ›Ä AI ğŸ”Š", value=True)
    image_mode = st.toggle("MÃ³d generovÃ¡nÃ­ obrÃ¡zkÅ¯ ğŸ¨")
    model_choice = st.selectbox("Model AI:", ["gemini-2.5-flash-lite", "gemini-1.5-pro"])
    st.divider()
    st.write("ğŸ¤ **Mluv na S.M.A.R.T.a:**")
    audio_input = mic_recorder(start_prompt="NahrÃ¡vat hlas ğŸ™ï¸", stop_prompt="Odeslat âš¡", key='mic')

# NaÄtenÃ­ klÃ­ÄÅ¯
api_keys = [st.secrets.get(f"GOOGLE_API_KEY_{i}") for i in range(1, 11) if st.secrets.get(f"GOOGLE_API_KEY_{i}")]

st.title("ğŸ¤– S.M.A.R.T. TerminÃ¡l")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if "image_url" in msg:
            st.image(msg["image_url"])

# --- BEZPEÄŒNÃ‰ ZPRACOVÃNÃ VSTUPU ---
input_text = st.chat_input("NapiÅ¡ nebo pouÅ¾ij mikrofon...")

# Oprava KeyError: Kontrola, zda audio_input existuje a obsahuje klÃ­Ä 'text'
if audio_input is not None:
    if isinstance(audio_input, dict) and audio_input.get('text'):
        input_text = audio_input['text']

if input_text:
    now = datetime.now().strftime("%H:%M:%S")
    st.session_state.messages.append({"role": "user", "content": input_text})
    
    with st.chat_message("user"):
        st.write(input_text)

    log_entry = {"time": now, "user_text": input_text, "ai_text": "ZpracovÃ¡vÃ¡m..."}
    global_store["logs"].append(log_entry)
    current_log_index = len(global_store["logs"]) - 1

    if image_mode:
        image_url = f"https://pollinations.ai/p/{input_text.replace(' ', '_')}?width=1024&height=1024&seed=42"
        response_text = f"Generuji obrÃ¡zek pro: {input_text}"
        with st.chat_message("assistant"):
            st.write(response_text)
            st.image(image_url)
        st.session_state.messages.append({"role": "assistant", "content": response_text, "image_url": image_url})
        global_store["logs"][current_log_index]["ai_text"] = "[ObrÃ¡zek]"
        if voice_enabled:
            speak_text("ObrÃ¡zek je hotovÃ½.")
    
    else:
        chat_context = []
        for m in st.session_state.messages[:-1]:
            role = "user" if m["role"] == "user" else "model"
            if "content" in m:
                chat_context.append({"role": role, "parts": [m["content"]]})

        response_text = "VÅ¡echna jÃ¡dra offline."
        for i, key in enumerate(api_keys):
            key_id = i + 1
            if global_store["key_status"].get(key_id) == "âŒ LIMIT": continue
            try:
                genai.configure(api_key=key)
                model = genai.GenerativeModel(model_choice)
                chat = model.start_chat(history=chat_context)
                res = chat.send_message(input_text)
                response_text = res.text
                break 
            except Exception as e:
                if "429" in str(e): global_store["key_status"][key_id] = "âŒ LIMIT"

        with st.chat_message("assistant"):
            st.write(response_text)
            if voice_enabled:
                speak_text(response_text)
        
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        global_store["logs"][current_log_index]["ai_text"] = response_text
